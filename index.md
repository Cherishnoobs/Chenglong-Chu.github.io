---
layout: homepage
---

## Hey 🙋‍♂️！

I'm Chenglong Chu.
Currently, I am a Research Engineer at the Kwai Keye team, focusing on pre-training and evaluation of multimodal foundation models 🌟. I have contributed to the development and deployment of the Keye-VL model series 🚀. My core work involves high-quality data curation, instruction tuning, scalable training pipeline design, and distributed acceleration 💻⚡, with the goal of continuously exploring and advancing the capabilities of multimodal large models.

I pursued my Master’s degree at the INCODAT Lab of Dalian University of Technology, under the supervision of Prof. Fangming Zhong 📚👨‍🏫. During my graduate studies, I primarily worked on multimodal feature alignment and large-scale pre-training, which laid a methodological and engineering foundation for building unified and scalable multimodal foundation models in an industrial setting.

## Research Interests 🧠🔍
- Unified Understanding-Generation Models: End-to-end multimodal instruction tuning, image/audio/video generation 🎨🔊🎥

- Multimodal Reasoning: Structured/programmatic reasoning (CoT/ToT), native multimodal reasoning 

- Efficient Pre-training: Data synthesis and curation, long-sequence modeling, perception enhancement, distributed training & acceleration 

- Evaluation & Safety: Multimodal benchmark development, alignment robustness, risk and bias mitigation 

{% include_relative _includes/publications.md %}


