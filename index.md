---
layout: homepage
---

## Hey ğŸ™‹â€â™‚ï¸ï¼

I'm Chenglong Chu.
Currently, I am a Research Engineer at the Kwai Keye team, focusing on pre-training and evaluation of multimodal foundation models ğŸŒŸ. I have contributed to the development and deployment of the Keye-VL model series ğŸš€. My core work involves high-quality data curation, instruction tuning, scalable training pipeline design, and distributed acceleration ğŸ’»âš¡, with the goal of continuously exploring and advancing the capabilities of multimodal large models.

I pursued my Masterâ€™s degree at the INCODAT Lab of Dalian University of Technology, under the supervision of Prof. Fangming Zhong ğŸ“šğŸ‘¨â€ğŸ«. During my graduate studies, I primarily worked on multimodal feature alignment and large-scale pre-training, which laid a methodological and engineering foundation for building unified and scalable multimodal foundation models in an industrial setting.

## Research Interests ğŸ§ ğŸ”
- Unified Understanding-Generation Models: End-to-end multimodal instruction tuning, image/audio/video generation ğŸ¨ğŸ”ŠğŸ¥

- Multimodal Reasoning: Structured/programmatic reasoning (CoT/ToT), native multimodal reasoning 

- Efficient Pre-training: Data synthesis and curation, long-sequence modeling, perception enhancement, distributed training & acceleration 

- Evaluation & Safety: Multimodal benchmark development, alignment robustness, risk and bias mitigation 

{% include_relative _includes/publications.md %}


