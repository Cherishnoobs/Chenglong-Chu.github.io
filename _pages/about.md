---
layout: about
title: about
permalink: /
subtitle: Engineer @ <a href='https://kwai-keye.github.io/'>Kwai Keye Team</a>

profile:
  align: right
  image: prof_pic.png
  image_circular: false # crops the image to make it circular
  more_info: >
    <p>cherish1357785883@gmail.com</p>

selected_papers: true # includes a list of papers marked as "selected={true}"
social: true # includes social icons at the bottom of the page

announcements:
  enabled: false # includes a list of news items
  scrollable: true # adds a vertical scroll bar if there are more than 3 news items
  limit: 5 # leave blank to include all the news in the `_news` folder

latest_posts:
  enabled: false
  scrollable: true # adds a vertical scroll bar if there are more than 3 new posts items
  limit: 3 # leave blank to include all the blog posts
---

I am Chenglong Chu, an Engineer at [Kwai Keye Team](https://kwai-keye.github.io/). I received my Master's degree from [INCODAT](http://www.ubinec.org/) Lab, Dalian University of Technology, advised by [Prof. Fangming Zhong](http://ubinec.org/zfm/cn/index.html). I received my B.Eng. in Software Engineering from Changzhou University.

My current research interests focus on multi-modal feature alignment and multi-modal large model pre-training. With the increasingly strong trend of multi-modal integration in the community, I hope to focus on the following areas in the future:

- **Lightweight and efficient generative large models**: Most of the current mainstream large models are bloated and clumsy. By studying the compression acceleration methods for generative large models, we can reduce the deployment cost of large models and make large models better used in the real world.

- **Multi-modality large models & Embodied Intelligence**: Traditional computer vision research paradigms struggle to adapt flexibly to the complex physical rules of the real world. Large models based on multi-modality are poised to break through these limitations in the future.
